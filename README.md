# ðŸŽ¯ End-to-End Data Pipeline Project with dbt & Snowflake  

## ðŸ”¹ Project Overview  
In this project, I implemented a **modern ELT pipeline** using:  
- **Amazon S3** â†’ as the landing zone for raw data (Extract & Load)  
- **Snowflake** â†’ as the cloud data warehouse  
- **dbt (Data Build Tool)** â†’ for data transformations (T in ELT)  
- **Power BI** â†’ as the reporting & visualization layer  

This workflow follows the standard **ELT architecture** used in real-world data teams.  

---

## ðŸ”¹ Architecture Flow  
![Project Architecture](./Images/DBTProject.png)  
*Figure: End-to-End Pipeline Architecture using S3, Snowflake, dbt, and Power BI*  

1. **Extract & Load**  
   - Raw data is dumped into **Amazon S3**.  
   - Loaded directly into **Snowflake (Raw Layer)** without any transformations.  

2. **Staging Layer (Snowflake + dbt)**  
   - dbt models create **staging tables** that clean and standardize raw data.  
   - Ensures data consistency without altering raw data.  

3. **Development / Business Layer (Snowflake + dbt)**  
   - dbt transforms staging tables into **fact & dimension tables** (star schema).  
   - Business-ready tables are created for analytics.  

4. **Analytics & Reporting (Power BI)**  
   - Power BI connects to Snowflake.  
   - Business users/analysts can directly query trusted, transformed data.  

---

## ðŸ”¹ Key Learnings from this Project  
- âœ… Understood **dbt core concepts** (models, seeds, sources, materializations)  
- âœ… Learned **snapshots** to track historical changes (SCD Type 2)  
- âœ… Explored **testing in dbt** to ensure data quality (no nulls, unique values, valid relationships)  
- âœ… Practiced **documentation in dbt**, making pipelines more maintainable & shareable  
- âœ… Built **fact & dimension tables** (modularity & structured data)  
- âœ… Experienced how dbt makes collaboration easier by logging, versioning, and documenting transformations  

---

## ðŸ”¹ Why This Matters  
This project simulates how **data engineers** and **analytics engineers** work in companies:  
- **Raw data stays untouched** (always available for validation)  
- **dbt ensures clean, modular, documented transformations**  
- **Power BI delivers insights** using trusted and tested data  

---

âœ¨ This project helped me **master the core of dbt** while seeing its role in a real-world pipeline.  
Itâ€™s a strong foundation to scale into **advanced topics** like orchestration, CI/CD for data, and performance optimization.  
